{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"src/archive/user_reviews.csv\")\n",
    "\n",
    "df = df.drop([\"isVerified\", \"isSuperReviewer\", \"hasSpoilers\", \"hasProfanity\", \n",
    "              \"userRealm\", 'reviewId', 'score', 'userDisplayName'], axis=1)\n",
    "\n",
    "# df = df.groupby(\"userId\").head(5)\n",
    "#df.to_csv(\"src/processed/user_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"src/processed/user_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df.sample(frac=0.4, random_state=42)\n",
    "# df_reduced.to_csv('df_reduced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userId e movieId indicizzati con valori numerici\n",
    "def create_id_mapping(df, column):\n",
    "    unique_ids = df[column].unique()\n",
    "    id_mapping = {id_: idx for idx, id_ in enumerate(unique_ids)}\n",
    "    return id_mapping\n",
    "\n",
    "# valori sostituiti nei campi originali\n",
    "user_id_mapping = create_id_mapping(df_reduced, 'userId')\n",
    "df_reduced['userId'] = df_reduced['userId'].map(user_id_mapping)\n",
    "\n",
    "movie_id_mapping = create_id_mapping(df_reduced, 'movieId')\n",
    "df_reduced['movieId'] = df_reduced['movieId'].map(movie_id_mapping)\n",
    "\n",
    "\n",
    "# Salvataggio mapping dati originali-indicizzati\n",
    "# mapping per userId originale e indexed\n",
    "user_mapping_df = pd.DataFrame(list(user_id_mapping.items()), columns=['userId_original', 'userId_index'])\n",
    "user_mapping_df.to_csv('user_id_mapping.csv', index=False)\n",
    "\n",
    "# mapping per movieId originale e indexed\n",
    "movie_mapping_df = pd.DataFrame(list(movie_id_mapping.items()), columns=['movieId_original', 'movieId_index'])\n",
    "movie_mapping_df.to_csv('movie_id_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing delle recensioni\n",
    "\n",
    "# rimossi tag html\n",
    "def remove_html_tags(text):\n",
    "    if text:\n",
    "        return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    return text\n",
    "\n",
    "# rimossi spazi bianchi multipli e a capo extra\n",
    "def clean_spaces_and_line_breaks(text):\n",
    "    if text:\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# rimossi singoli e doppi apici extra\n",
    "def remove_quotes(text):\n",
    "    if text:\n",
    "        text = text.strip('\"')\n",
    "        text = text.replace('\"', '')\n",
    "        return text\n",
    "    return text\n",
    "\n",
    "# rimossi caratteri speciali e emoji\n",
    "def remove_non_ascii(text):\n",
    "    if text:\n",
    "        # ritorna solo caratteri ASCII\n",
    "        return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    return text\n",
    "\n",
    "def clean_csv_df(df):\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    if 'quote' in df_cleaned.columns:\n",
    "        df_cleaned['quote'] = df_cleaned['quote'].apply(remove_html_tags)\n",
    "        df_cleaned['quote'] = df_cleaned['quote'].apply(clean_spaces_and_line_breaks)\n",
    "        df_cleaned['quote'] = df_cleaned['quote'].apply(remove_quotes)\n",
    "        df_cleaned['quote'] = df_cleaned['quote'].apply(remove_non_ascii)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "df_cleaned = clean_csv_df(df_reduced)\n",
    "df_cleaned.to_csv('user_reviews_final_reduced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23172\\265837714.py:2: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"src/processed/user_reviews_processed.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [movieId, rating, quote, creationDate, userId]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(\"src/processed/user_reviews_processed.csv\")\n",
    "df = df.sample(10000, random_state=42)\n",
    "\n",
    "# Check for NaN or infinite values in any column and remove those rows\n",
    "df_cleaned = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Print the rows that were removed\n",
    "invalid_rows = df[~df.index.isin(df_cleaned.index)]\n",
    "print(invalid_rows)\n",
    "\n",
    "df_cleaned['userId'] = df_cleaned['userId'].astype(int)\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv('src/processed/user_reviews_processed_mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # processing delle recensioni, applicata su csv \n",
    "\n",
    "# # rimossi tag html\n",
    "# def remove_html_tags(text):\n",
    "#     if text:\n",
    "#         return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "#     return text\n",
    "\n",
    "# # rimossi spazi bianchi multipli e a capo extra\n",
    "# def clean_spaces_and_line_breaks(text):\n",
    "#     if text:\n",
    "#         text = re.sub(r'\\s+', ' ', text).strip()\n",
    "#         return text\n",
    "#     return text\n",
    "\n",
    "# # rimossi singoli e doppi apici extra\n",
    "# def remove_quotes(text):\n",
    "#     if text:\n",
    "#         text = text.strip('\"')\n",
    "#         text = text.replace('\"', '')\n",
    "#         return text\n",
    "#     return text\n",
    "\n",
    "# # rimossi caratteri speciali e emoji\n",
    "# def remove_non_ascii(text):\n",
    "#     if text:\n",
    "#         # ritorna solo caratteri ASCII\n",
    "#         return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "#     return text\n",
    "\n",
    "# def clean_csv(input_file, output_file):\n",
    "#     with open(input_file, newline='', encoding='utf-8') as infile:\n",
    "#         reader = csv.reader(infile)\n",
    "#         rows = []\n",
    "#         current_row = None\n",
    "\n",
    "#         for row in reader:\n",
    "#             # se la riga è vuota, la ignoriamo\n",
    "#             if not any(row):\n",
    "#                 continue\n",
    "            \n",
    "#             # se la riga contiene solo una colonna, è una continuazione della precedente\n",
    "#             if len(row) == 1 and current_row is not None:\n",
    "#                 current_row[2] += \" \" + row[0] \n",
    "#             else:\n",
    "#                 # aggiunta la riga precedente completata\n",
    "#                 if current_row:\n",
    "#                     current_row[2] = remove_html_tags(current_row[2])\n",
    "#                     current_row[2] = clean_spaces_and_line_breaks(current_row[2]) \n",
    "#                     current_row[2] = remove_quotes(current_row[2])  \n",
    "#                     current_row[2] = remove_non_ascii(current_row[2])\n",
    "#                     rows.append(current_row)\n",
    "                \n",
    "#                 # nuova riga corrente\n",
    "#                 current_row = row\n",
    "        \n",
    "#         # aggiunta l'ultima riga\n",
    "#         if current_row:\n",
    "#             current_row[2] = remove_html_tags(current_row[2])  \n",
    "#             current_row[2] = clean_spaces_and_line_breaks(current_row[2]) \n",
    "#             current_row[2] = remove_quotes(current_row[2]) \n",
    "#             current_row[2] = remove_non_ascii(current_row[2])\n",
    "#             rows.append(current_row)\n",
    "    \n",
    "#     with open(output_file, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "#         writer = csv.writer(outfile)\n",
    "#         writer.writerows(rows)\n",
    "\n",
    "#     print(f\"File pulito salvato come '{output_file}'.\")\n",
    "\n",
    "\n",
    "# df_reduced.to_csv('user_reviews_input.csv', index=False)\n",
    "# input_file = 'user_reviews_input.csv' \n",
    "# output_file = 'user_reviews_cleaned.csv' \n",
    "# clean_csv(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
